# Transformer_Seq2Seq
Model Description: Implementation of the Transformer Model Architecture in Keras.

Deep Learning Problem: The purpose of this project is to take in input a sequence of words corresponding to a random permutation of a given english sentence, and reconstruct the original sentence.

Problem Category: seq2seq problem.
