# Transformer_Seq2Seq
### Model Description: Implementation of the Transformer Model Architecture in Keras.

âœï¸ Deep Learning Problem: The purpose of this project is to take in input a sequence of words corresponding to a random permutation of a given english sentence, and reconstruct the original sentence.

ğŸ”´ Problem Category: seq2seq problem.
